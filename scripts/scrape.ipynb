{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/daozhuw/ADS_ASMT2/generic-real-estate-consulting-project-group-22/scripts/scrape.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/daozhuw/ADS_ASMT2/generic-real-estate-consulting-project-group-22/scripts/scrape.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m N_PAGES:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/daozhuw/ADS_ASMT2/generic-real-estate-consulting-project-group-22/scripts/scrape.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=41'>42</a>\u001b[0m     url \u001b[39m=\u001b[39m BASE_URL \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/rent/?postcode=\u001b[39m\u001b[39m{\u001b[39;00mpostcode\u001b[39m}\u001b[39;00m\u001b[39m&sort=price-desc&page=\u001b[39m\u001b[39m{\u001b[39;00mpage\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/daozhuw/ADS_ASMT2/generic-real-estate-consulting-project-group-22/scripts/scrape.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m     bs_object \u001b[39m=\u001b[39m BeautifulSoup(requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49mheaders)\u001b[39m.\u001b[39;49mtext, \u001b[39m\"\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/daozhuw/ADS_ASMT2/generic-real-estate-consulting-project-group-22/scripts/scrape.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39m# find the unordered list (ul) elements which are the results, then\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/daozhuw/ADS_ASMT2/generic-real-estate-consulting-project-group-22/scripts/scrape.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39m# find all href (a) tags that are from the base_url website.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/daozhuw/ADS_ASMT2/generic-real-estate-consulting-project-group-22/scripts/scrape.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mif\u001b[39;00m bs_object\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mul\u001b[39m\u001b[39m\"\u001b[39m, {\u001b[39m\"\u001b[39m\u001b[39mdata-testid\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m}) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39minitialize_soup(\u001b[39mself\u001b[39m)\n\u001b[1;32m    332\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed()\n\u001b[1;32m    334\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mreset()\n\u001b[0;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mfeed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarkup)\n\u001b[1;32m    452\u001b[0m \u001b[39m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendData()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/builder/_htmlparser.py:399\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    397\u001b[0m parser\u001b[39m.\u001b[39msoup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoup\n\u001b[1;32m    398\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     parser\u001b[39m.\u001b[39;49mfeed(markup)\n\u001b[1;32m    400\u001b[0m     parser\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    401\u001b[0m \u001b[39mexcept\u001b[39;00m HTMLParseError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoahead(\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/html/parser.py:170\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m startswith(\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m, i):\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m starttagopen\u001b[39m.\u001b[39mmatch(rawdata, i): \u001b[39m# < + letter\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_starttag(i)\n\u001b[1;32m    171\u001b[0m     \u001b[39melif\u001b[39;00m startswith(\u001b[39m\"\u001b[39m\u001b[39m</\u001b[39m\u001b[39m\"\u001b[39m, i):\n\u001b[1;32m    172\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_endtag(i)\n",
      "File \u001b[0;32m/usr/lib/python3.10/html/parser.py:344\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_startendtag(tag, attrs)\n\u001b[1;32m    343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_starttag(tag, attrs)\n\u001b[1;32m    345\u001b[0m     \u001b[39mif\u001b[39;00m tag \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCDATA_CONTENT_ELEMENTS:\n\u001b[1;32m    346\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_cdata_mode(tag)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/bs4/builder/_htmlparser.py:154\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_starttag\u001b[0;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39m#print(\"START\", name)\u001b[39;00m\n\u001b[1;32m    153\u001b[0m sourceline, sourcepos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetpos()\n\u001b[0;32m--> 154\u001b[0m tag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msoup\u001b[39m.\u001b[39;49mhandle_starttag(\n\u001b[1;32m    155\u001b[0m     name, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, attr_dict, sourceline\u001b[39m=\u001b[39;49msourceline,\n\u001b[1;32m    156\u001b[0m     sourcepos\u001b[39m=\u001b[39;49msourcepos\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m tag \u001b[39mand\u001b[39;00m tag\u001b[39m.\u001b[39mis_empty_element \u001b[39mand\u001b[39;00m handle_empty_element:\n\u001b[1;32m    159\u001b[0m     \u001b[39m# Unlike other parsers, html.parser doesn't send separate end tag\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[39m# events for empty-element tags. (It's handled in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# don't want handle_endtag() to cross off any previous end\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# events for tags of this name.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_endtag(name, check_already_closed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A very simple and basic web scraping script. Feel free to\n",
    "use this as a source of inspiration, but, make sure to attribute\n",
    "it if you do so.\n",
    "\n",
    "This is by no means production code.\n",
    "\"\"\"\n",
    "# built-in imports\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from json import dump\n",
    "from pprint import pprint\n",
    "from urllib.request import urlopen\n",
    "from xml.dom.minidom import Attr\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import requests\n",
    "\n",
    "# user packages\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# constants\n",
    "BASE_URL = \"https://www.domain.com.au\"\n",
    "N_PAGES = range(1, 10)  # update this to your liking\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# begin code\n",
    "url_links = []\n",
    "property_metadata = defaultdict(dict)\n",
    "\n",
    "df = pd.read_csv('../data/curated/postcode_vic.csv')\n",
    "df = df.drop_duplicates(subset=['postcode'])\n",
    "df = df['postcode']\n",
    "\n",
    "for postcode in df:\n",
    "    # generate list of urls to visit\n",
    "    for page in N_PAGES:\n",
    "\n",
    "        url = BASE_URL + f\"/rent/?postcode={postcode}&sort=price-desc&page={page}\"\n",
    "        bs_object = BeautifulSoup(requests.get(url, headers=headers).text, \"html.parser\")\n",
    "\n",
    "        # find the unordered list (ul) elements which are the results, then\n",
    "        # find all href (a) tags that are from the base_url website.\n",
    "        if bs_object.find(\"ul\", {\"data-testid\": \"results\"}) is None:\n",
    "            break\n",
    "        else:\n",
    "            index_links = bs_object.find(\"ul\", {\"data-testid\": \"results\"}).findAll(\n",
    "                \"a\", href=re.compile(f\"{BASE_URL}/*\")  # the `*` denotes wildcard any\n",
    "            )\n",
    "\n",
    "        for link in index_links:\n",
    "            # if its a property address, add it to the list\n",
    "            if \"address\" in link[\"class\"]:\n",
    "                url_links.append(link[\"href\"])\n",
    "\n",
    "\n",
    "# for each url, scrape some basic metadata\n",
    "for property_url in url_links[1:]:\n",
    "    bs_object = BeautifulSoup(\n",
    "        requests.get(property_url, headers=headers, verify=False).text, \"html.parser\"\n",
    "    )\n",
    "\n",
    "    # looks for the header class to get property name\n",
    "    property_metadata[property_url][\"name\"] = bs_object.find(\n",
    "        \"h1\", {\"class\": \"css-164r41r\"}\n",
    "    ).text\n",
    "\n",
    "    # looks for the div containing a summary title for cost\n",
    "    property_metadata[property_url][\"cost_text\"] = bs_object.find(\n",
    "        \"div\", {\"data-testid\": \"listing-details__summary-title\"}\n",
    "    ).text\n",
    "\n",
    "    \n",
    "    # extract coordinates from the hyperlink provided\n",
    "    # i'll let you figure out what this does :P\n",
    "    property_metadata[property_url][\"coordinates\"] = [\n",
    "        float(coord)\n",
    "        for coord in re.findall(\n",
    "            r\"destination=([-\\s,\\d\\.]+)\",  # use regex101.com here if you need to\n",
    "            bs_object.find(\n",
    "                \"a\", {\"target\": \"_blank\", \"rel\": \"noopener noreferer\"}\n",
    "            ).attrs[\"href\"],\n",
    "        )[0].split(\",\")\n",
    "    ]\n",
    "    \n",
    "\n",
    "    attr_dict = [feature.text for feature in bs_object \\\n",
    "            .find(\"div\", {\"data-testid\": \"property-features\"}) \\\n",
    "            .findAll(\"span\", {\"data-testid\": \"property-features-text-container\"})]\n",
    "    \n",
    "    if attr_dict == []:\n",
    "        property_metadata[property_url]['rooms'] = 'null'\n",
    "        property_metadata[property_url]['baths'] = 'null'\n",
    "        property_metadata[property_url]['parking'] = 'null'\n",
    "        property_metadata[property_url]['area'] = 'null'\n",
    "    else:\n",
    "        property_metadata[property_url]['rooms'] = re.findall(r'\\d\\s[A-Za-z]+', attr_dict[0])\n",
    "        property_metadata[property_url]['baths'] = re.findall(r'\\d\\s[A-Za-z]+', attr_dict[1])\n",
    "        property_metadata[property_url]['parking'] = re.findall(r'\\d\\s[A-Za-z]+', attr_dict[2])\n",
    "        if len(attr_dict) == 4:\n",
    "            property_metadata[property_url]['area'] = attr_dict[3]\n",
    "\n",
    "\n",
    "    property_metadata[property_url][\"desc\"] = re.sub(\n",
    "        r\"<br\\/>\", \"\\n\", str(bs_object.find(\"p\"))\n",
    "    ).strip(\"</p>\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# output to example json in data/raw/\n",
    "with open(\"../data/raw/example.json\", \"w\") as f:\n",
    "    dump(property_metadata, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
